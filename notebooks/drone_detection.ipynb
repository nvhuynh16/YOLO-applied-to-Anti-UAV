{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti-UAV Drone Detection with YOLOv9\n",
    "\n",
    "This notebook demonstrates real-time drone detection in videos using YOLOv9 fine-tuned on the Anti-UAV dataset.\n",
    "\n",
    "## Features\n",
    "- **Video Processing**: Detect drones frame-by-frame in video files\n",
    "- **Annotated Output**: Generate videos with red bounding boxes around detected drones\n",
    "- **JSON Predictions**: Export predictions in Anti-UAV format (visible.json)\n",
    "- **Performance Metrics**: Track detection confidence and coverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'scripts'))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'models' / 'yolov9'))\n",
    "\n",
    "from inference import DroneDetector\n",
    "\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "WEIGHTS_PATH = PROJECT_ROOT / 'runs' / 'train' / 'quick-test' / 'weights' / 'best.pt'\n",
    "VIDEO_PATH = PROJECT_ROOT / 'data' / 'subset' / '20190925_101846_1_2' / 'visible.mp4'\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs'\n",
    "\n",
    "# Detection parameters\n",
    "CONF_THRESHOLD = 0.25  # Confidence threshold\n",
    "IOU_THRESHOLD = 0.45   # NMS IoU threshold\n",
    "DEVICE = '0'           # CUDA device ('0', '1', ...) or 'cpu'\n",
    "\n",
    "print(f\"Weights: {WEIGHTS_PATH}\")\n",
    "print(f\"Video: {VIDEO_PATH}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = DroneDetector(\n",
    "    weights_path=str(WEIGHTS_PATH),\n",
    "    device=DEVICE,\n",
    "    conf_thres=CONF_THRESHOLD,\n",
    "    iou_thres=IOU_THRESHOLD,\n",
    "    img_size=640\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup output paths\nvideo_name = VIDEO_PATH.parent.name  # Use parent directory name (e.g., \"20190925_101846_1_2\")\noutput_video_path = OUTPUT_DIR / 'videos' / f\"{video_name}_visible_detected.mp4\"\noutput_json_path = OUTPUT_DIR / 'predictions' / f\"{video_name}_visible.json\"\n\noutput_video_path.parent.mkdir(parents=True, exist_ok=True)\noutput_json_path.parent.mkdir(parents=True, exist_ok=True)\n\n# Run inference\nresults = detector.process_video(\n    video_path=VIDEO_PATH,\n    output_video_path=output_video_path,\n    output_json_path=output_json_path,\n    draw_boxes=True,\n    box_color=(0, 0, 255),  # Red\n    box_thickness=2\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "with open(output_json_path, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "total_frames = len(predictions['exist'])\n",
    "detected_frames = sum(predictions['exist'])\n",
    "detection_rate = detected_frames / total_frames * 100\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DETECTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total frames: {total_frames}\")\n",
    "print(f\"Frames with detections: {detected_frames}\")\n",
    "print(f\"Detection rate: {detection_rate:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sample frames\n",
    "cap = cv2.VideoCapture(str(output_video_path))\n",
    "\n",
    "# Get frames at different timestamps\n",
    "sample_frames_idx = [0, total_frames // 4, total_frames // 2, 3 * total_frames // 4]\n",
    "sample_frames = []\n",
    "\n",
    "for idx in sample_frames_idx:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        sample_frames.append((idx, frame_rgb))\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (idx, frame) in enumerate(sample_frames):\n",
    "    axes[i].imshow(frame)\n",
    "    axes[i].set_title(f'Frame {idx} - Detection: {\"Yes\" if predictions[\"exist\"][idx] == 1 else \"No\"}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Output Video\n",
    "\n",
    "**Note**: Video playback may not work in all Jupyter environments. If the video doesn't play, check the output file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display video (if supported)\n",
    "try:\n",
    "    display(Video(str(output_video_path), width=800))\n",
    "except Exception as e:\n",
    "    print(f\"Video display not supported in this environment: {e}\")\n",
    "    print(f\"\\nOutput video saved at: {output_video_path}\")\n",
    "    print(f\"Open it with any video player to view the results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detection timeline\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(predictions['exist'], linewidth=0.5)\n",
    "plt.fill_between(range(len(predictions['exist'])), predictions['exist'], alpha=0.3)\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Detection (1=Yes, 0=No)')\n",
    "plt.title('Drone Detection Timeline')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding Box Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze bounding box sizes\n",
    "box_areas = []\n",
    "for exist, rect in zip(predictions['exist'], predictions['gt_rect']):\n",
    "    if exist == 1:\n",
    "        x, y, w, h = rect\n",
    "        area = w * h\n",
    "        box_areas.append(area)\n",
    "\n",
    "if box_areas:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(box_areas, bins=30, edgecolor='black')\n",
    "    plt.xlabel('Bounding Box Area (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Detection Sizes')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(box_areas, linewidth=1)\n",
    "    plt.xlabel('Detection Index')\n",
    "    plt.ylabel('Bounding Box Area (pixels)')\n",
    "    plt.title('Detection Size Over Time')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average box area: {sum(box_areas)/len(box_areas):.2f} pixels\")\n",
    "    print(f\"Min box area: {min(box_areas):.2f} pixels\")\n",
    "    print(f\"Max box area: {max(box_areas):.2f} pixels\")\n",
    "else:\n",
    "    print(\"No detections found in video.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"video\": str(VIDEO_PATH.name),\n",
    "    \"total_frames\": total_frames,\n",
    "    \"detected_frames\": detected_frames,\n",
    "    \"detection_rate\": f\"{detection_rate:.2f}%\",\n",
    "    \"avg_box_area\": f\"{sum(box_areas)/len(box_areas):.2f}\" if box_areas else \"N/A\",\n",
    "    \"output_video\": str(output_video_path),\n",
    "    \"output_json\": str(output_json_path)\n",
    "}\n",
    "\n",
    "print(json.dumps(summary, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}